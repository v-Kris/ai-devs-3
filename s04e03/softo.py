import os
import requests
from bs4 import BeautifulSoup
from urllib.parse import urljoin
from langfuse.openai import OpenAI
from common.report_helpers import send_report
import json

# Initialize Langfuse OpenAI client
client = OpenAI()

def analyze_page_content(content, question):
    """Analizuje zawartoÅ›Ä‡ strony pod kÄ…tem odpowiedzi na pytanie."""
    system_prompt = """JesteÅ› asystentem analizujÄ…cym zawartoÅ›Ä‡ stron internetowych.
    Twoim zadaniem jest:
    1. OkreÅ›liÄ‡, czy strona zawiera odpowiedÅº na pytanie w przekazanym tekÅ›cie
    2. JeÅ›li tak - wyodrÄ™bniÄ‡ odpowiedÅº
    3. JeÅ›li nie - przeanalizowaÄ‡ dostÄ™pne linki i zaproponowaÄ‡ listÄ™ najbardziej obiecujÄ…cych linkÃ³w do eksploracji
    
    Otrzymasz sÅ‚ownik zawierajÄ…cy:
    - "text": treÅ›Ä‡ strony
    - "links": listÄ™ dostÄ™pnych linkÃ³w, gdzie kaÅ¼dy link ma "href" (URL) i "text" (tekst wyÅ›wietlany)
    
    Odpowiedz TYLKO w formacie: 
    {"contains_answer": bool, "answer": str|null, "next_links": [str]|null}
    
    Dla next_links uÅ¼yj dokÅ‚adnych wartoÅ›ci href z listy dostÄ™pnych linkÃ³w."""

    user_prompt = f"""Pytanie: {question}
    ZawartoÅ›Ä‡ strony: {content}
    
    Czy ta strona zawiera odpowiedÅº na pytanie? JeÅ›li tak, podaj odpowiedÅº.
    JeÅ›li nie, wskaÅ¼ ktÃ³ry link wyglÄ…da najbardziej obiecujÄ…co (jeÅ›li sÄ…)."""

    completion = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_prompt}
        ]
    )
    
    try:
        return completion.choices[0].message.content
    except Exception as e:
        print(f"âŒ BÅ‚Ä…d podczas analizy LLM: {e}")
        return None

def search_softoai():
    base_url = "https://softo.ag3nts.org"
    visited_links = set()
    answers = {}

    def visit_page(url, question_number, question):
        if url in visited_links:
            print(f"ğŸ”„ Pomijam juÅ¼ odwiedzony URL: {url}")
            return None
        
        print(f"\nğŸŒ Odwiedzam stronÄ™: {url}")
        visited_links.add(url)

        try:
            page = requests.get(url)
            page.raise_for_status()
            soup = BeautifulSoup(page.content, 'html.parser')
            print(f"âœ… Pobrano stronÄ™: {url}")

            links = []
            for link in soup.find_all('a', href=True):
                href = link.get('href')
                text = link.get_text(strip=True)
                links.append({"href": href, "text": text})

            content = {
                "text": soup.get_text(separator=' ', strip=True),
                "links": links
            }
            
            analysis = analyze_page_content(content, question)
            
            if analysis:
                try:
                    result = json.loads(analysis)
                    
                    if result.get("contains_answer"):
                        answers[question_number] = result["answer"]
                        print(f"ğŸ’¡ Znaleziono odpowiedÅº na pytanie {question_number}: {result['answer']}")
                        return True
                    elif result.get("next_links"):
                        for next_url in result["next_links"]:
                            if next_url not in visited_links:
                                if not next_url.startswith('http'):
                                    next_url = urljoin(base_url, next_url)
                                print(f"ğŸ” PrÃ³bujÄ™ link: {next_url}")
                                if visit_page(next_url, question_number, question):
                                    return True
                        
                        print("âŒ Å»aden z sugerowanych linkÃ³w nie zawieraÅ‚ odpowiedzi")
                        return False
                except json.JSONDecodeError as e:
                    print(f"âŒ BÅ‚Ä…d podczas parsowania JSON: {e}")
                    return False
            
            print(f"âŒ Nie znaleziono odpowiedzi na tej stronie")
            return False

        except requests.exceptions.RequestException as e:
            print(f"âŒ BÅ‚Ä…d podczas pobierania strony {url}: {e}")
            return False

    # Pobierz pytania
    try:
        api_key = os.getenv('CENTRALA_API_KEY')
        questions_url = f"https://centrala.ag3nts.org/data/{api_key}/softo.json"
        response = requests.get(questions_url)
        questions = response.json()
        print(f"ğŸ“ Pobrano pytania: {questions}")
    except Exception as e:
        print(f"âŒ BÅ‚Ä…d podczas pobierania pytaÅ„: {e}")
        return {}

    # Przeszukaj stronÄ™ dla kaÅ¼dego pytania
    for question_number, question in questions.items():
        print(f"\nğŸ“‹ Rozpoczynam szukanie odpowiedzi na pytanie {question_number}: {question}")
        
        # Reset visited links for each question
        visited_links = set()
        
        # Start searching from the base URL
        visit_page(base_url, question_number, question)

    return answers

if __name__ == "__main__":
    print("\nğŸš€ Rozpoczynam przeszukiwanie strony SoftoAI...")
    answers = search_softoai()
    print(f"ğŸ“¤ WysyÅ‚ana odpowiedÅº: {answers}")

    try:
        response = send_report(answers, "softo")
        print(f"ğŸ“¨ Report response: {response}")
    except Exception as e:
        print(f"âŒ Error sending report: {str(e)}")
        raise